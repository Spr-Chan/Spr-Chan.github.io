<!DOCTYPE html>












  


<html class="theme-next gemini use-motion" lang="zh-CN">
<head><meta name="generator" content="Hexo 3.9.0">
  <meta charset="UTF-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
<meta name="theme-color" content="#222">






















<link rel="stylesheet" href="/lib/font-awesome/css/font-awesome.min.css?v=4.7.0">

<link rel="stylesheet" href="/css/main.css?v=7.2.0">


  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png?v=7.2.0">


  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png?v=7.2.0">


  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png?v=7.2.0">


  <link rel="mask-icon" href="/images/logo.svg?v=7.2.0" color="#222">







<script id="hexo.configurations">
  var NexT = window.NexT || {};
  var CONFIG = {
    root: '/',
    scheme: 'Gemini',
    version: '7.2.0',
    sidebar: {"position":"left","display":"post","offset":12,"onmobile":false},
    back2top: {"enable":true,"sidebar":false,"scrollpercent":false},
    copycode: {"enable":false,"show_result":false,"style":null},
    fancybox: false,
    fastclick: false,
    lazyload: false,
    tabs: true,
    motion: {"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},
    algolia: {
      applicationID: '',
      apiKey: '',
      indexName: '',
      hits: {"per_page":10},
      labels: {"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}
    },
    translation: {
      copy_button: '复制',
      copy_success: '复制成功',
      copy_failure: '复制失败'
    }
  };
</script>



  <meta name="description" content="前言&amp;emsp;&amp;emsp;四天入门Python（慕课网地址），三天入门简单爬虫（慕课网地址），八天撸完180行的代码，一路磕磕绊绊，一路的bugbugbug……，索性还是以比较快的速度解决了女票的要求（爬来的数据给女票写小论文用）。直接先码代码贴上，以后有空再对代码进行详解吧……">
<meta name="keywords" content="Python爬虫,评论爬取,汽车导购网站,买车选车,大数据购车">
<meta property="og:type" content="article">
<meta property="og:title" content="Python爬虫实战：汽车导购网站评论爬取（大数据帮你买到心仪好车）">
<meta property="og:url" content="http://yoursite.com/2019/07/11/Python爬虫实战：汽车导购网站评论爬取（大数据帮你买到心仪好车）/index.html">
<meta property="og:site_name" content="Morty写字的地方">
<meta property="og:description" content="前言&amp;emsp;&amp;emsp;四天入门Python（慕课网地址），三天入门简单爬虫（慕课网地址），八天撸完180行的代码，一路磕磕绊绊，一路的bugbugbug……，索性还是以比较快的速度解决了女票的要求（爬来的数据给女票写小论文用）。直接先码代码贴上，以后有空再对代码进行详解吧……">
<meta property="og:locale" content="zh-CN">
<meta property="og:image" content="http://ww2.sinaimg.cn/large/006tNc79gy1g4w8ju4h6sj31hc0kwguv.jpg">
<meta property="og:updated_time" content="2019-07-11T14:39:53.917Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Python爬虫实战：汽车导购网站评论爬取（大数据帮你买到心仪好车）">
<meta name="twitter:description" content="前言&amp;emsp;&amp;emsp;四天入门Python（慕课网地址），三天入门简单爬虫（慕课网地址），八天撸完180行的代码，一路磕磕绊绊，一路的bugbugbug……，索性还是以比较快的速度解决了女票的要求（爬来的数据给女票写小论文用）。直接先码代码贴上，以后有空再对代码进行详解吧……">
<meta name="twitter:image" content="http://ww2.sinaimg.cn/large/006tNc79gy1g4w8ju4h6sj31hc0kwguv.jpg">





  
  
  <link rel="canonical" href="http://yoursite.com/2019/07/11/Python爬虫实战：汽车导购网站评论爬取（大数据帮你买到心仪好车）/">



<script id="page.configurations">
  CONFIG.page = {
    sidebar: "",
  };
</script>

  <title>Python爬虫实战：汽车导购网站评论爬取（大数据帮你买到心仪好车） | Morty写字的地方</title>
  












  <noscript>
  <style>
  .use-motion .motion-element,
  .use-motion .brand,
  .use-motion .menu-item,
  .sidebar-inner,
  .use-motion .post-block,
  .use-motion .pagination,
  .use-motion .comments,
  .use-motion .post-header,
  .use-motion .post-body,
  .use-motion .collection-title { opacity: initial; }

  .use-motion .logo,
  .use-motion .site-title,
  .use-motion .site-subtitle {
    opacity: initial;
    top: initial;
  }

  .use-motion .logo-line-before i { left: initial; }
  .use-motion .logo-line-after i { right: initial; }
  </style>
</noscript>

</head>

<body itemscope itemtype="http://schema.org/WebPage" lang="zh-CN">

  
  
    
  

  <div class="container sidebar-position-left page-post-detail">
    <div class="headband"></div>

    <header id="header" class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-wrapper">
  <div class="site-meta">
    

    <div class="custom-logo-site-title">
      <a href="/" class="brand" rel="start">
        <span class="logo-line-before"><i></i></span>
        <span class="site-title">Morty写字的地方</span>
        <span class="logo-line-after"><i></i></span>
      </a>
    </div>
    
    
  </div>

  <div class="site-nav-toggle">
    <button aria-label="切换导航栏">
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
    </button>
  </div>
</div>



<nav class="site-nav">
  
    <ul id="menu" class="menu">
      
        
        
        
          
          <li class="menu-item menu-item-home">

    
    
      
    

    

    <a href="/" rel="section"><i class="menu-item-icon fa fa-fw fa-home"></i> <br>首页</a>

  </li>
        
        
        
          
          <li class="menu-item menu-item-tags">

    
    
      
    

    

    <a href="/tags/" rel="section"><i class="menu-item-icon fa fa-fw fa-tags"></i> <br>标签</a>

  </li>
        
        
        
          
          <li class="menu-item menu-item-categories">

    
    
      
    

    

    <a href="/categories/" rel="section"><i class="menu-item-icon fa fa-fw fa-th"></i> <br>分类</a>

  </li>
        
        
        
          
          <li class="menu-item menu-item-archives">

    
    
      
    

    

    <a href="/archives/" rel="section"><i class="menu-item-icon fa fa-fw fa-archive"></i> <br>归档</a>

  </li>

      
      
    </ul>
  

  

  
</nav>



</div>
    </header>

    


    <main id="main" class="main">
      <div class="main-inner">
        <div class="content-wrap">
          
            

          
          <div id="content" class="content">
            

  <div id="posts" class="posts-expand">
    

  

  
  
  

  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2019/07/11/Python爬虫实战：汽车导购网站评论爬取（大数据帮你买到心仪好车）/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Spring Chan">
      <meta itemprop="description" content="There is only one heroism in the world：to see the world as it is and to love it.">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Morty写字的地方">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">Python爬虫实战：汽车导购网站评论爬取（大数据帮你买到心仪好车）

              
            
          </h1>
        

        <div class="post-meta">

          
          
          

          
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              

              
                
              

              <time title="创建时间：2019-07-11 06:37:38 / 修改时间：07:39:53" itemprop="dateCreated datePublished" datetime="2019-07-11T06:37:38-07:00">2019-07-11</time>
            </span>
          

          
            

            
          

          

          
            
            
              
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="fa fa-comment-o"></i>
                </span>
            
                <span class="post-meta-item-text">评论数：</span>
                <a href="/2019/07/11/Python爬虫实战：汽车导购网站评论爬取（大数据帮你买到心仪好车）/#comments" itemprop="discussionUrl">
                  <span class="post-comments-count valine-comment-count" data-xid="/2019/07/11/Python爬虫实战：汽车导购网站评论爬取（大数据帮你买到心仪好车）/" itemprop="commentCount"></span>
                </a>
              </span>
            
          

          
          

          

          

          <br>
          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        <h3 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h3><p>&emsp;&emsp;四天入门Python（<a href="https://www.imooc.com/code/3255" target="_blank" rel="noopener">慕课网地址</a>），三天入门简单爬虫（<a href="https://www.imooc.com/video/10674" target="_blank" rel="noopener">慕课网地址</a>），八天撸完180行的代码，一路磕磕绊绊，一路的bugbugbug……，索性还是以比较快的速度解决了女票的要求（爬来的数据给女票写小论文用）。直接先码代码贴上，以后有空再对代码进行详解吧……</p>
<a id="more"></a>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br><span class="line">167</span><br><span class="line">168</span><br><span class="line">169</span><br><span class="line">170</span><br><span class="line">171</span><br><span class="line">172</span><br><span class="line">173</span><br><span class="line">174</span><br><span class="line">175</span><br><span class="line">176</span><br><span class="line">177</span><br><span class="line">178</span><br><span class="line">179</span><br><span class="line">180</span><br></pre></td><td class="code"><pre><span class="line">#爬取爱卡汽车网站所有“纯电动”汽车的“车名”、“价格”、“级别”、“续航”、“电量”,并输出为html</span><br><span class="line">#-*- coding: utf-8 -*-</span><br><span class="line">from bs4 <span class="keyword">import</span> BeautifulSoup</span><br><span class="line"><span class="keyword">import</span> re</span><br><span class="line">from urllib <span class="keyword">import</span> request</span><br><span class="line"></span><br><span class="line">#8个电动汽车的总页面的url</span><br><span class="line">first_urls = []</span><br><span class="line"><span class="function"><span class="keyword">for</span> i in <span class="title">range</span><span class="params">(<span class="number">1</span>, <span class="number">9</span>)</span>:</span></span><br><span class="line"><span class="function">    first_urls.<span class="title">append</span><span class="params">(<span class="string">'http://newcar.xcar.com.cn/car/0-0-0-0-0-0-0-0-0-0-0-'</span>+str(i)</span>+'-1-0/')</span></span><br><span class="line"><span class="function"></span></span><br><span class="line"><span class="function">#8个总页面下的所有款车的url</span></span><br><span class="line"><span class="function">nodes_num </span>= []</span><br><span class="line"><span class="keyword">for</span> url in first_urls:</span><br><span class="line">    response = request.urlopen(url)</span><br><span class="line">    html_cont = response.read()</span><br><span class="line">    soup = BeautifulSoup(html_cont.decode(<span class="string">'gb2312'</span>),<span class="string">'html.parser'</span>)</span><br><span class="line">    link_nodes = soup.find_all('a', class_="car_search_ps_list_a")#link_nodes是一个list列表</span><br><span class="line">    <span class="keyword">for</span> i in link_nodes:</span><br><span class="line">        nodes_num.append(<span class="string">'http://newcar.xcar.com.cn'</span>+str(i[<span class="string">'href'</span>]))</span><br><span class="line"></span><br><span class="line">#构造datas-------------------------------------------------------------</span><br><span class="line">datas = []</span><br><span class="line">nodes_rev = []#收集有用的url，加工成口碑url存到此列表中</span><br><span class="line">count = <span class="number">0</span></span><br><span class="line"><span class="keyword">for</span> url_num in nodes_num:</span><br><span class="line">    count+=<span class="number">1</span></span><br><span class="line">    </span><br><span class="line">    response_num = request.urlopen(url_num)</span><br><span class="line">    html_cont_num = response_num.read()</span><br><span class="line">    soup_num = BeautifulSoup(html_cont_num.decode(<span class="string">'gbk'</span>),<span class="string">'html.parser'</span>)</span><br><span class="line">    </span><br><span class="line">    url_rev = url_num+<span class="string">'review.htm'</span></span><br><span class="line">    response_rev = request.urlopen(url_rev)</span><br><span class="line">    html_cont_rev = response_rev.read()</span><br><span class="line">    soup_rev = BeautifulSoup(html_cont_rev.decode(<span class="string">'gbk'</span>),<span class="string">'html.parser'</span>)</span><br><span class="line">    </span><br><span class="line">    res_data = &#123;&#125;#dict列表，每轮res_data列表包含13个key（车名、价格......）</span><br><span class="line">    <span class="keyword">try</span>:</span><br><span class="line">        link_node01 = soup_num.find(<span class="string">"span"</span>, class_=<span class="string">"lt_f1"</span>).get_text()</span><br><span class="line">        link_node02 = soup_num.find(<span class="string">'div'</span>, class_=<span class="string">"tt_h1"</span>).find(<span class="string">"h1"</span>).get_text()</span><br><span class="line">        res_data[<span class="string">'车名'</span>] = link_node01+link_node02</span><br><span class="line">        </span><br><span class="line">        link_node03 = soup_num.find(<span class="string">'a'</span>, class_=<span class="string">"com_price_menu"</span>).get_text()</span><br><span class="line">        #print "价格：", link_node03,"万"</span><br><span class="line">        res_data[<span class="string">'价格'</span>] = link_node03</span><br><span class="line">        </span><br><span class="line">        link_node04 = soup_num.find_all(<span class="string">'li'</span>, class_=<span class="string">"w163"</span>)</span><br><span class="line">        res_data[<span class="string">'级别'</span>] = link_node04[<span class="number">0</span>].get_text()[<span class="number">4</span>:-<span class="number">1</span>]</span><br><span class="line">        res_data[<span class="string">'续航(km)'</span>] = re.findall(<span class="string">"\d+"</span>,link_node04[<span class="number">1</span>].get_text())[-<span class="number">1</span>]</span><br><span class="line">        </span><br><span class="line">        <span class="string">''</span><span class="string">'link_node05 = soup_num.find('</span>a<span class="string">', onclick="clicklog(124783);").get_text()</span></span><br><span class="line"><span class="string">        #print "电量：", re.findall("\d+",link_node05)[0]+"kWh"</span></span><br><span class="line"><span class="string">        res_data['</span>电量<span class="string">'] = re.findall("\d+",link_node05)[0]'</span><span class="string">''</span></span><br><span class="line">        </span><br><span class="line">        link_node06 = soup_rev.find(<span class="string">'div'</span>, class_=<span class="string">"synthesis"</span>).get_text()</span><br><span class="line">        res_data[<span class="string">'综合评分'</span>] = re.findall(r<span class="string">'\d+.\d+'</span>, link_node06)[<span class="number">0</span>]</span><br><span class="line">        </span><br><span class="line">        link_node07 = soup_rev.find_all(<span class="string">'div'</span>, class_=<span class="string">"bg"</span>)</span><br><span class="line">        res_data[<span class="string">'外观'</span>] = re.findall(r<span class="string">'\d+.\d+'</span>, link_node07[<span class="number">0</span>].get_text())[<span class="number">0</span>]</span><br><span class="line">        res_data[<span class="string">'内饰'</span>] = re.findall(r<span class="string">'\d+.\d+'</span>, link_node07[<span class="number">1</span>].get_text())[<span class="number">0</span>]</span><br><span class="line">        res_data[<span class="string">'空间'</span>] = re.findall(r<span class="string">'\d+.\d+'</span>, link_node07[<span class="number">2</span>].get_text())[<span class="number">0</span>]</span><br><span class="line">        res_data[<span class="string">'舒适'</span>] = re.findall(r<span class="string">'\d+.\d+'</span>, link_node07[<span class="number">3</span>].get_text())[<span class="number">0</span>]</span><br><span class="line">        res_data[<span class="string">'续航'</span>] = re.findall(r<span class="string">'\d+.\d+'</span>, link_node07[<span class="number">4</span>].get_text())[<span class="number">0</span>]</span><br><span class="line">        res_data[<span class="string">'动力'</span>] = re.findall(r<span class="string">'\d+.\d+'</span>, link_node07[<span class="number">5</span>].get_text())[<span class="number">0</span>]</span><br><span class="line">        res_data[<span class="string">'操控'</span>] = re.findall(r<span class="string">'\d+.\d+'</span>, link_node07[<span class="number">6</span>].get_text())[<span class="number">0</span>]</span><br><span class="line">        res_data[<span class="string">'性价比'</span>] = re.findall(r<span class="string">'\d+.\d+'</span>, link_node07[<span class="number">7</span>].get_text())[<span class="number">0</span>]</span><br><span class="line">        </span><br><span class="line">        datas.append(res_data)</span><br><span class="line">        nodes_rev.append(url_rev)</span><br><span class="line">        print(count)</span><br><span class="line">    except:</span><br><span class="line">        print (count, <span class="string">"craw failed"</span>)</span><br><span class="line"></span><br><span class="line">#构造datas_dis----------------------------------------------------------------------------</span><br><span class="line">datas_dis = []</span><br><span class="line">number = <span class="number">0</span></span><br><span class="line">for url in nodes_rev:#nodes_rev里存的是有用口碑url</span><br><span class="line">    url_page = []</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">try</span>:</span><br><span class="line">        response_ = request.urlopen(url)</span><br><span class="line">        html_cont_ = response_.read()</span><br><span class="line">        soup_ = BeautifulSoup(html_cont_.decode(<span class="string">'gbk'</span>),<span class="string">'html.parser'</span>)</span><br><span class="line">        </span><br><span class="line">        link_nodes = soup_.find_all('a', href="javascript:void(0);", rel="nofollow", class_="page")#取最后一页的页数</span><br><span class="line">        last_page = re.findall(r'\d+', link_nodes[-1]['onclick'])[0]#最后一页的页数，是字符型数据，如'4'</span><br><span class="line">        </span><br><span class="line">        <span class="function"><span class="keyword">for</span> i in <span class="title">range</span><span class="params">(<span class="number">1</span>, <span class="keyword">int</span>(last_page)</span>+1):</span></span><br><span class="line"><span class="function">            url_page.<span class="title">append</span><span class="params">(<span class="string">'http://newcar.xcar.com.cn/auto/index.php?r=reputation/reputation/GetAjaxKbList3&amp;page='</span>+str(i)</span>+'&amp;pserid</span>=<span class="string">'+re.findall(r'</span>\d+<span class="string">', url)[0]+'</span>&amp;jh=<span class="number">0</span>&amp;wd=<span class="number">0</span><span class="string">')</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    except:</span></span><br><span class="line"><span class="string">        url_page.append(url)</span></span><br><span class="line"><span class="string">    </span></span><br><span class="line"><span class="string">    number+=1</span></span><br><span class="line"><span class="string">    datas_02 = []</span></span><br><span class="line"><span class="string">    cout = 0#‘发表时间’、‘购车地点’和‘爱车评价’的插入点索引随url_的变化而变化</span></span><br><span class="line"><span class="string">    try:</span></span><br><span class="line"><span class="string">        for url_ in url_page:</span></span><br><span class="line"><span class="string">            response = request.urlopen(url_)</span></span><br><span class="line"><span class="string">            html_cont = response.read()</span></span><br><span class="line"><span class="string">            soup = BeautifulSoup(html_cont.decode('</span>gbk<span class="string">'),'</span>html.parser<span class="string">')</span></span><br><span class="line"><span class="string">            </span></span><br><span class="line"><span class="string">            link_node_01 = soup.find_all('</span>div<span class="string">', class_="name_lf")</span></span><br><span class="line"><span class="string">            for i in link_node_01:</span></span><br><span class="line"><span class="string">                res_data = &#123;&#125;</span></span><br><span class="line"><span class="string">                res_data['</span>评论人<span class="string">'] = re.findall(r'</span>\A(.+)<span class="string">',i.get_text()[4:])[0]#(.+)和.+都可以，‘\A’ 匹配字符串开头，r'</span>\A(.+)<span class="string">'表示匹配字符串开头的任意字符（空格或换行符前）</span></span><br><span class="line"><span class="string">                datas_02.append(res_data)</span></span><br><span class="line"><span class="string">            </span></span><br><span class="line"><span class="string">            link_node_02 = soup.find_all('</span>div<span class="string">', class_="publish")</span></span><br><span class="line"><span class="string">            cout_ = cout</span></span><br><span class="line"><span class="string">            for i in link_node_02:</span></span><br><span class="line"><span class="string">                datas_02[cout_]['</span>发表时间<span class="string">'] = re.findall(r'</span>\d+-\d+-\d+<span class="string">', i.get_text())[0]</span></span><br><span class="line"><span class="string">                cout_+=1</span></span><br><span class="line"><span class="string">            </span></span><br><span class="line"><span class="string">            link_node_03 = soup.find_all('</span>div<span class="string">', class_="list_infor")</span></span><br><span class="line"><span class="string">            cout_ = cout</span></span><br><span class="line"><span class="string">            for i in link_node_03:</span></span><br><span class="line"><span class="string">                datas_02[cout_]['</span>购车地点<span class="string">'] = re.findall(r'</span>[[](.*?)[]]<span class="string">', i.get_text().replace('</span>\n<span class="string">','</span><span class="string">').replace('</span>\n<span class="string">','</span><span class="string">').replace('</span> <span class="string">','</span><span class="string">'))[0]#先去掉所有空格和换行，再提取[xx市]中的xx市</span></span><br><span class="line"><span class="string">                cout_+=1</span></span><br><span class="line"><span class="string">            </span></span><br><span class="line"><span class="string">            cout_ = cout</span></span><br><span class="line"><span class="string">            link_node_04 = soup.find_all('</span>div<span class="string">', class_="review_post")</span></span><br><span class="line"><span class="string">            for i in link_node_04:</span></span><br><span class="line"><span class="string">                datas_02[cout_]['</span>爱车评价<span class="string">'] = re.sub('</span>[\n]+<span class="string">', '</span>\n<span class="string">', i.get_text().strip())#strip()去掉头尾的空格和空行,re.sub('</span>[\n]+<span class="string">', '</span>\n<span class="string">', '</span>xxx<span class="string">')去掉字符串xxx中多余的空行</span></span><br><span class="line"><span class="string">                cout_+=1</span></span><br><span class="line"><span class="string">            </span></span><br><span class="line"><span class="string">            cout+=len(link_node_01)</span></span><br><span class="line"><span class="string">            </span></span><br><span class="line"><span class="string">        print(number, "craw sucessful")</span></span><br><span class="line"><span class="string">            </span></span><br><span class="line"><span class="string">    except:</span></span><br><span class="line"><span class="string">        print (number, "craw failed")</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    datas_dis.append(datas_02)</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">#datas列表和datas_dis列表相结合--------------------------------------------------------------</span></span><br><span class="line"><span class="string">tot = []#形式为：“tot = [[ , ], [ , ], [ , ],......, [ , ]]”每一个元素都是list列表，每个元素包含一个datas元素和datas_dis元素</span></span><br><span class="line"><span class="string">for i in datas:</span></span><br><span class="line"><span class="string">    tot_ = []</span></span><br><span class="line"><span class="string">    tot_.append(i)</span></span><br><span class="line"><span class="string">    tot.append(tot_)</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">num_tot = 0</span></span><br><span class="line"><span class="string">for j in datas_dis:</span></span><br><span class="line"><span class="string">    tot[num_tot].append(j)</span></span><br><span class="line"><span class="string">    num_tot += 1</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">#建立一个文件的输出对象fout，文件名为12121.html, 输出各项数据-----------------------------------</span></span><br><span class="line"><span class="string">#Python默认的编码是：ascii，要输出为utf-8的话，要加encoding = '</span>utf-<span class="number">8</span><span class="string">'</span></span><br><span class="line"><span class="string">fout = open('</span><span class="number">12121</span>.html<span class="string">', '</span>w<span class="string">', encoding = '</span>utf-<span class="number">8</span><span class="string">')</span></span><br><span class="line"><span class="string">fout.write("&lt;html&gt;")</span></span><br><span class="line"><span class="string">fout.write("&lt;body&gt;")</span></span><br><span class="line"><span class="string">fout.write("&lt;table&gt;")</span></span><br><span class="line"><span class="string">for i in tot:</span></span><br><span class="line"><span class="string">    for j in i[1]:</span></span><br><span class="line"><span class="string">        fout.write("&lt;tr&gt;")</span></span><br><span class="line"><span class="string">        fout.write("&lt;td&gt;%s&lt;/td&gt;" % i[0]['</span>车名<span class="string">'])</span></span><br><span class="line"><span class="string">        fout.write("&lt;td&gt;%s&lt;/td&gt;" % i[0]['</span>价格<span class="string">'])</span></span><br><span class="line"><span class="string">        fout.write("&lt;td&gt;%s&lt;/td&gt;" % i[0]['</span>级别<span class="string">'])</span></span><br><span class="line"><span class="string">        fout.write("&lt;td&gt;%s&lt;/td&gt;" % i[0]['</span>续航(km)<span class="string">'])</span></span><br><span class="line"><span class="string">        #fout.write("&lt;td&gt;%s&lt;/td&gt;" % i[0]['</span>电量<span class="string">'])</span></span><br><span class="line"><span class="string">        fout.write("&lt;td&gt;%s&lt;/td&gt;" % i[0]['</span>综合评分<span class="string">'])</span></span><br><span class="line"><span class="string">        fout.write("&lt;td&gt;%s&lt;/td&gt;" % i[0]['</span>外观<span class="string">'])</span></span><br><span class="line"><span class="string">        fout.write("&lt;td&gt;%s&lt;/td&gt;" % i[0]['</span>内饰<span class="string">'])</span></span><br><span class="line"><span class="string">        fout.write("&lt;td&gt;%s&lt;/td&gt;" % i[0]['</span>空间<span class="string">'])</span></span><br><span class="line"><span class="string">        fout.write("&lt;td&gt;%s&lt;/td&gt;" % i[0]['</span>舒适<span class="string">'])</span></span><br><span class="line"><span class="string">        fout.write("&lt;td&gt;%s&lt;/td&gt;" % i[0]['</span>续航<span class="string">'])</span></span><br><span class="line"><span class="string">        fout.write("&lt;td&gt;%s&lt;/td&gt;" % i[0]['</span>动力<span class="string">'])</span></span><br><span class="line"><span class="string">        fout.write("&lt;td&gt;%s&lt;/td&gt;" % i[0]['</span>操控<span class="string">'])</span></span><br><span class="line"><span class="string">        fout.write("&lt;td&gt;%s&lt;/td&gt;" % i[0]['</span>性价比<span class="string">'])</span></span><br><span class="line"><span class="string">        fout.write("&lt;td&gt;%s&lt;/td&gt;" % j['</span>评论人<span class="string">'])</span></span><br><span class="line"><span class="string">        fout.write("&lt;td&gt;%s&lt;/td&gt;" % j['</span>发表时间<span class="string">'])</span></span><br><span class="line"><span class="string">        fout.write("&lt;td&gt;%s&lt;/td&gt;" % j.get('</span>购车地点<span class="string">'))</span></span><br><span class="line"><span class="string">        fout.write("&lt;td&gt;%s&lt;/td&gt;" % j.get('</span>爱车评价<span class="string">'))</span></span><br><span class="line"><span class="string">        fout.write("&lt;/tr&gt;")</span></span><br><span class="line"><span class="string">fout.write("&lt;/table&gt;")</span></span><br><span class="line"><span class="string">fout.write("&lt;/body&gt;")</span></span><br><span class="line"><span class="string">fout.write("&lt;/html&gt;")</span></span><br><span class="line"><span class="string">fout.close()</span></span><br></pre></td></tr></table></figure>

<p>最后输出的是html文件，爬到了800条左右的评论（其中不乏几撮水军），用excel编辑完就是如下效果：<br><img src="http://ww2.sinaimg.cn/large/006tNc79gy1g4w8ju4h6sj31hc0kwguv.jpg" alt></p>
<p>&emsp;&emsp;后期的话，如果将网站所有车型的评论都爬取下来，估计得有几十万条评论，分析这些评论数据也会对自己将来购车有所帮助。</p>

      
    </div>

    

    
      
    

    
    
    

    

    
      
    
    

    

    <footer class="post-footer">
      
        
          
        
        <div class="post-tags">
          
            <a href="/tags/Python爬虫/" rel="tag"># Python爬虫</a>
          
            <a href="/tags/评论爬取/" rel="tag"># 评论爬取</a>
          
            <a href="/tags/汽车导购网站/" rel="tag"># 汽车导购网站</a>
          
            <a href="/tags/买车选车/" rel="tag"># 买车选车</a>
          
            <a href="/tags/大数据购车/" rel="tag"># 大数据购车</a>
          
        </div>
      

      
      
      

      
        <div class="post-nav">
          <div class="post-nav-next post-nav-item">
            
              <a href="/2019/07/07/三张图搞透第一范式(1NF)、第二范式(2NF)和第三范式(3NF)的区别/" rel="next" title="三张图搞透第一范式（1NF）、第二范式（2NF）和第三范式（3NF）的区别">
                <i class="fa fa-chevron-left"></i> 三张图搞透第一范式（1NF）、第二范式（2NF）和第三范式（3NF）的区别
              </a>
            
          </div>

          <span class="post-nav-divider"></span>

          <div class="post-nav-prev post-nav-item">
            
              <a href="/2019/07/11/C++  指向动态分配的指针数组的指针/" rel="prev" title="【C++】指向动态分配的指针数组的指针">
                【C++】指向动态分配的指针数组的指针 <i class="fa fa-chevron-right"></i>
              </a>
            
          </div>
        </div>
      

      
      
    </footer>
  </div>
  
  
  
  </article>


  </div>


          </div>
          

  
    <div class="comments" id="comments">
    </div>

  



        </div>
        
          
  
  <div class="sidebar-toggle">
    <div class="sidebar-toggle-line-wrap">
      <span class="sidebar-toggle-line sidebar-toggle-line-first"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-last"></span>
    </div>
  </div>

  <aside id="sidebar" class="sidebar">
    <div class="sidebar-inner">

      

      
        <ul class="sidebar-nav motion-element">
          <li class="sidebar-nav-toc sidebar-nav-active" data-target="post-toc-wrap">
            文章目录
          </li>
          <li class="sidebar-nav-overview" data-target="site-overview-wrap">
            站点概览
          </li>
        </ul>
      

      <div class="site-overview-wrap sidebar-panel">
        <div class="site-overview">
          <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
            
              <p class="site-author-name" itemprop="name">Spring Chan</p>
              <div class="site-description motion-element" itemprop="description">There is only one heroism in the world：to see the world as it is and to love it.</div>
          </div>

          
            <nav class="site-state motion-element">
              
                <div class="site-state-item site-state-posts">
                
                  <a href="/archives/">
                
                    <span class="site-state-item-count">36</span>
                    <span class="site-state-item-name">日志</span>
                  </a>
                </div>
              

              
                
                
                <div class="site-state-item site-state-categories">
                  
                    
                      <a href="/categories/">
                    
                  
                    
                    
                      
                    
                    <span class="site-state-item-count">1</span>
                    <span class="site-state-item-name">分类</span>
                  </a>
                </div>
              

              
                
                
                <div class="site-state-item site-state-tags">
                  
                    
                      <a href="/tags/">
                    
                  
                    
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                    <span class="site-state-item-count">107</span>
                    <span class="site-state-item-name">标签</span>
                  </a>
                </div>
              
            </nav>
          

          

          

          

          

          
          

          
        </div>
      </div>

      
      <!--noindex-->
        <div class="post-toc-wrap motion-element sidebar-panel sidebar-panel-active">
          <div class="post-toc">

            
            
            
            

            
              <div class="post-toc-content"><ol class="nav"><li class="nav-item nav-level-3"><a class="nav-link" href="#前言"><span class="nav-number">1.</span> <span class="nav-text">前言</span></a></li></ol></div>
            

          </div>
        </div>
      <!--/noindex-->
      

      

    </div>
  </aside>
  <div id="sidebar-dimmer"></div>


        
      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="footer-inner">
        <div class="copyright">&copy; <span itemprop="copyrightYear">2019</span>
  <span class="with-love" id="animate">
    <i class="fa fa-user"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">Spring Chan</span>

  

  
</div>


  <div class="powered-by">由 <a href="https://hexo.io" class="theme-link" rel="noopener" target="_blank">Hexo</a> 强力驱动 v3.9.0</div>



  <span class="post-meta-divider">|</span>



  <div class="theme-info">主题 – <a href="https://theme-next.org" class="theme-link" rel="noopener" target="_blank">NexT.Gemini</a> v7.2.0</div>




        








        
      </div>
    </footer>

    
      <div class="back-to-top">
        <i class="fa fa-arrow-up"></i>
        
      </div>
    

    

    
  </div>

  

<script>
  if (Object.prototype.toString.call(window.Promise) !== '[object Function]') {
    window.Promise = null;
  }
</script>










  
  





  
    
    
  
  <script color="85,85,85" opacity="0.8" zindex="-1" count="129" src="/lib/canvas-nest/canvas-nest.min.js"></script>









  
  <script src="/lib/jquery/index.js?v=3.4.1"></script>

  
  <script src="/lib/velocity/velocity.min.js?v=1.2.1"></script>

  
  <script src="/lib/velocity/velocity.ui.min.js?v=1.2.1"></script>




  <script src="/js/utils.js?v=7.2.0"></script>

  <script src="/js/motion.js?v=7.2.0"></script>



  
  


  <script src="/js/affix.js?v=7.2.0"></script>

  <script src="/js/schemes/pisces.js?v=7.2.0"></script>




  
  <script src="/js/scrollspy.js?v=7.2.0"></script>
<script src="/js/post-details.js?v=7.2.0"></script>



  <script src="/js/next-boot.js?v=7.2.0"></script>

  

  

  

  

  
  

  

<script src="https://cdn.jsdelivr.net/npm/valine@1.3.9/dist/Valine.min.js"></script>

<script>
  var GUEST = ['nick', 'mail', 'link'];
  var guest = 'nick,mail,link';
  guest = guest.split(',').filter(function(item) {
    return GUEST.indexOf(item) > -1;
  });
  new Valine({
    el: '#comments',
    verify: false,
    notify: false,
    appId: 'jWkhbmugUPCnD6VY9AeQEwLd-gzGzoHsz',
    appKey: 'TqFQzOiCxOp6LReSMhNWresA',
    placeholder: 'Just go go',
    avatar: 'mm',
    meta: guest,
    pageSize: '10' || 10,
    visitor: false,
    lang: 'zh-cn' || 'zh-cn'
  });
</script>




  


  




  

  

  

  

  

  

  

  

  

  

  

  

  


  

</body>
</html>
